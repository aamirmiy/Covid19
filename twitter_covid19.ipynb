{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Covid19/March.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions\n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    #removing mentions\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        In the war against the global epidemic #corona...\n",
       "1        Dear liberals, Please do not pray for Corona v...\n",
       "2        Sir there is not treatment available for coron...\n",
       "3        Replying to #WHO \"Coronavirus confirmed as pan...\n",
       "4        #jharkhand @HemantSorenJMM @WeAreRanchi @WeAre...\n",
       "                               ...                        \n",
       "42313    The members of Tableegi jamaat in Sopore hosip...\n",
       "42314    Iranian state TV said Saturday the new coronav...\n",
       "42315    #Breaking | 5 more cases of Coronavirus have b...\n",
       "42316    CORONAVIRUS I'm not scared of the virus, I'm j...\n",
       "42317    Asalamu Alikum Good decision makers can make i...\n",
       "Name: Text, Length: 42318, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace tabs and spaces\n",
    "df['Text']= df['Text'].replace({'\\n':\" \",\"\\t\":\" \"})\n",
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dsk\n",
    "import multiprocessing as mp\n",
    "from dask.multiprocessing import get\n",
    "ddf = dsk.from_pandas(df,npartitions=4*mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Place', 'Query', 'Datetime', 'Text', 'retweets',\n",
       "       'favourites', 'hashtags', 'Text1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text1'] = df['Text'].apply(clean_tweets) #preprocessing using user defined functions\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text1']\n",
    "df = df.drop('Text1', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating subjectivity and Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subjectivity']=df['Text'].apply(getSubjectivity)\n",
    "df['Polarity']=df['Text'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Place', 'Query', 'Datetime', 'Text', 'retweets',\n",
       "       'favourites', 'hashtags', 'Subjectivity', 'Polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Place</th>\n",
       "      <th>Query</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-29 16:23:31+00:00</td>\n",
       "      <td>In war global epidemic coronavirus I donated ₹...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>#coronavirus #PMCARES</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-18 05:40:36+00:00</td>\n",
       "      <td>Dear liberals Please pray Corona virus cases g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-19 08:09:44+00:00</td>\n",
       "      <td>Sir treatment available corona virus Jharkhand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>covid19</td>\n",
       "      <td>2020-03-11 18:05:59+00:00</td>\n",
       "      <td>Replying WHO `` Coronavirus confirmed pandemic...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>#WHO #COVID19</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-26 08:26:04+00:00</td>\n",
       "      <td>jharkhand HemantSorenJMM WeAreRanchi WeAreDhan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#jharkhand</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>-0.058333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Place        Query                   Datetime  \\\n",
       "0           0  Jharkhand  coronavirus  2020-03-29 16:23:31+00:00   \n",
       "1           1  Jharkhand  coronavirus  2020-03-18 05:40:36+00:00   \n",
       "2           2  Jharkhand  coronavirus  2020-03-19 08:09:44+00:00   \n",
       "3           3  Jharkhand      covid19  2020-03-11 18:05:59+00:00   \n",
       "4           4  Jharkhand  coronavirus  2020-03-26 08:26:04+00:00   \n",
       "\n",
       "                                                Text  retweets  favourites  \\\n",
       "0  In war global epidemic coronavirus I donated ₹...         1           9   \n",
       "1  Dear liberals Please pray Corona virus cases g...         0           0   \n",
       "2     Sir treatment available corona virus Jharkhand         0           0   \n",
       "3  Replying WHO `` Coronavirus confirmed pandemic...         0           2   \n",
       "4  jharkhand HemantSorenJMM WeAreRanchi WeAreDhan...         0           0   \n",
       "\n",
       "                hashtags  Subjectivity  Polarity  \n",
       "0  #coronavirus #PMCARES      0.000000  0.000000  \n",
       "1                    NaN      0.400000 -0.150000  \n",
       "2                    NaN      0.400000  0.400000  \n",
       "3          #WHO #COVID19      0.597222  0.119444  \n",
       "4             #jharkhand      0.225000 -0.058333  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NewMARCH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling tweets accoridng to sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def emotion(tweet):\n",
    "    \n",
    "    def most_frequent(List): \n",
    "        return max(set(List), key = List.count) \n",
    "    \n",
    "    \n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    temp = []\n",
    "    cleanedList = []\n",
    "    i = 0\n",
    "    for word in word_tokens:\n",
    "        em = emot['emotion'].where(word == emot['word'])\n",
    "        cleanedList = [x for x in em if str(x) != 'nan']\n",
    "\n",
    "        if i == 0:\n",
    "            if not cleanedList:\n",
    "                continue\n",
    "            else:\n",
    "                temp = cleanedList\n",
    "        else:\n",
    "            if not cleanedList:\n",
    "                continue\n",
    "            else:\n",
    "                temp.append(cleanedList[0])\n",
    "        i += 1\n",
    "\n",
    "   # print(f'temp : {temp}, len(temp) : {len(temp)}')\n",
    "    if len(temp) == 0:\n",
    "        #print(f'return: neutral')\n",
    "        return 'neutral'\n",
    "    \n",
    "   # print(f'return: {most_frequent(temp)}')\n",
    "    \n",
    "    return most_frequent(temp)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"NewJune.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "emot = pd.read_csv(\"emotions.csv\")\n",
    "emot = pd.DataFrame(emot)\n",
    "emot.columns=['word', 'emotion']\n",
    "df['Text']=df['Text'].apply(str)\n",
    "df['sentiment'] = df['Text'].apply(emotion)\n",
    "#print(df.sentiment.unique())\n",
    "\n",
    "df.to_csv(\"june_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('april_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     38207\n",
       "joy          8155\n",
       "surprise     1722\n",
       "sadness      1583\n",
       "fear          689\n",
       "anger         591\n",
       "disgust        93\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     32181\n",
       "joy          5797\n",
       "surprise     1667\n",
       "sadness      1184\n",
       "fear         1020\n",
       "anger         285\n",
       "disgust       184\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('march_sentiment.csv')\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     33325\n",
       "joy          6444\n",
       "sadness      1993\n",
       "surprise     1991\n",
       "fear          546\n",
       "anger         476\n",
       "disgust       141\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('may_sentiment.csv')\n",
    "df2['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     35503\n",
       "joy          5846\n",
       "surprise     1852\n",
       "sadness      1556\n",
       "fear          605\n",
       "anger         391\n",
       "disgust       134\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_csv('june_sentiment.csv')\n",
    "df3['sentiment'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
