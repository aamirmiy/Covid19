{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Covid19/March.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions\n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    #removing mentions\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        In the war against the global epidemic #corona...\n",
       "1        Dear liberals, Please do not pray for Corona v...\n",
       "2        Sir there is not treatment available for coron...\n",
       "3        Replying to #WHO \"Coronavirus confirmed as pan...\n",
       "4        #jharkhand @HemantSorenJMM @WeAreRanchi @WeAre...\n",
       "                               ...                        \n",
       "42313    The members of Tableegi jamaat in Sopore hosip...\n",
       "42314    Iranian state TV said Saturday the new coronav...\n",
       "42315    #Breaking | 5 more cases of Coronavirus have b...\n",
       "42316    CORONAVIRUS I'm not scared of the virus, I'm j...\n",
       "42317    Asalamu Alikum Good decision makers can make i...\n",
       "Name: Text, Length: 42318, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace tabs and spaces\n",
    "df['Text']= df['Text'].replace({'\\n':\" \",\"\\t\":\" \"})\n",
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dsk\n",
    "import multiprocessing as mp\n",
    "from dask.multiprocessing import get\n",
    "ddf = dsk.from_pandas(df,npartitions=4*mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Place', 'Query', 'Datetime', 'Text', 'retweets',\n",
       "       'favourites', 'hashtags', 'Text1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text1'] = df['Text'].apply(clean_tweets) #preprocessing using user defined functions\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text1']\n",
    "df = df.drop('Text1', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating subjectivity and Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subjectivity']=df['Text'].apply(getSubjectivity)\n",
    "df['Polarity']=df['Text'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Place', 'Query', 'Datetime', 'Text', 'retweets',\n",
       "       'favourites', 'hashtags', 'Subjectivity', 'Polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Place</th>\n",
       "      <th>Query</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-29 16:23:31+00:00</td>\n",
       "      <td>In war global epidemic coronavirus I donated ₹...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>#coronavirus #PMCARES</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-18 05:40:36+00:00</td>\n",
       "      <td>Dear liberals Please pray Corona virus cases g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-19 08:09:44+00:00</td>\n",
       "      <td>Sir treatment available corona virus Jharkhand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>covid19</td>\n",
       "      <td>2020-03-11 18:05:59+00:00</td>\n",
       "      <td>Replying WHO `` Coronavirus confirmed pandemic...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>#WHO #COVID19</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2020-03-26 08:26:04+00:00</td>\n",
       "      <td>jharkhand HemantSorenJMM WeAreRanchi WeAreDhan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#jharkhand</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>-0.058333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Place        Query                   Datetime  \\\n",
       "0           0  Jharkhand  coronavirus  2020-03-29 16:23:31+00:00   \n",
       "1           1  Jharkhand  coronavirus  2020-03-18 05:40:36+00:00   \n",
       "2           2  Jharkhand  coronavirus  2020-03-19 08:09:44+00:00   \n",
       "3           3  Jharkhand      covid19  2020-03-11 18:05:59+00:00   \n",
       "4           4  Jharkhand  coronavirus  2020-03-26 08:26:04+00:00   \n",
       "\n",
       "                                                Text  retweets  favourites  \\\n",
       "0  In war global epidemic coronavirus I donated ₹...         1           9   \n",
       "1  Dear liberals Please pray Corona virus cases g...         0           0   \n",
       "2     Sir treatment available corona virus Jharkhand         0           0   \n",
       "3  Replying WHO `` Coronavirus confirmed pandemic...         0           2   \n",
       "4  jharkhand HemantSorenJMM WeAreRanchi WeAreDhan...         0           0   \n",
       "\n",
       "                hashtags  Subjectivity  Polarity  \n",
       "0  #coronavirus #PMCARES      0.000000  0.000000  \n",
       "1                    NaN      0.400000 -0.150000  \n",
       "2                    NaN      0.400000  0.400000  \n",
       "3          #WHO #COVID19      0.597222  0.119444  \n",
       "4             #jharkhand      0.225000 -0.058333  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NewMARCH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling tweets with IBM Watson Tone Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "version = '2020-07-15'\n",
    "ibmapi = 'apikey'\n",
    "urlf = 'given urlf from ibm'\n",
    "authenticator = IAMAuthenticator(ibmapi)\n",
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version=version,\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "tone_analyzer.set_service_url(urlf)\n",
    "\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"all.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# change the below line\n",
    "df = df.iloc[start:end] # ---- changes this ----\n",
    "\n",
    "i = 0\n",
    "text = \"Dear liberals Please pray Corona virus cases grow exponentially petty enmity current incumbent government The situation well controlled At least keep politics aside sake country Regards An Indian\"\n",
    "def sent(text):\n",
    "    global i\n",
    "    i += 1\n",
    "    tone_analysis = tone_analyzer.tone(\n",
    "        {'text': text},\n",
    "        content_type='application/json'\n",
    "    ).get_result()\n",
    "#     print(json.dumps(tone_analysis, indent=2))\n",
    "    x = json.dumps(tone_analysis, indent=2)\n",
    "    y = json.loads(x)\n",
    "    try:\n",
    "        y['document_tone']['tones'][0]['tone_name']\n",
    "\n",
    "    except:\n",
    "        print(f\"{i} Neutral\")\n",
    "        return \"Neutral\"\n",
    "    \n",
    "    \n",
    "    if y['document_tone']['tones'][0]['tone_name'] == 'Tentative':\n",
    "        try:\n",
    "            res = y['document_tone']['tones'][1]['tone_name']\n",
    "        except:\n",
    "            res = \"Neutral\"\n",
    "    else:\n",
    "        res = y['document_tone']['tones'][0]['tone_name']\n",
    "        \n",
    "    print(f\"{i} {res}\")\n",
    "    return res\n",
    "\n",
    "# sent(text)\n",
    "df['ibm_sentiment'] = df['Text'].apply(sent)\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv(\"filename.csv\") # ---- and change this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
